# ============================================
# ðŸ§  Parkinsonâ€™s Disease Prediction Notebook (Extended with Reports)
# ============================================

# --- 1. Imports ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os, json, joblib

from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

from sklearn.decomposition import PCA

# Deep Learning (Keras)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.optimizers import Adam

# --- 2. Load Data ---
df = pd.read_csv("data/parkinsons.csv")
print("Shape:", df.shape)
df.head()

# --- 3. EDA ---
print(df.describe().T)
print("Missing values:\n", df.isnull().sum())

# Target distribution
plt.figure(figsize=(5,4))
sns.countplot(x="status", data=df, palette="Set2")
plt.title("Target Distribution (0=Healthy, 1=Parkinsonâ€™s)")
plt.savefig("assets/target_distribution.png")
plt.show()

# Correlation heatmap
plt.figure(figsize=(12,10))
sns.heatmap(df.corr(), cmap="coolwarm", center=0)
plt.title("Feature Correlation Heatmap")
plt.savefig("assets/correlation_heatmap.png")
plt.show()

# PCA visualization
X = df.drop("status", axis=1)
y = df["status"]
X_scaled = StandardScaler().fit_transform(X)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
plt.figure(figsize=(6,5))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y, palette="Set1")
plt.title("PCA Projection (2D)")
plt.savefig("assets/pca_projection.png")
plt.show()

# --- 4. Define Models ---

# Keras NN builder
def create_nn():
    model = Sequential()
    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['AUC'])
    return model

models = {
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(),
    "Extra Trees": ExtraTreesClassifier(n_estimators=200, random_state=42),
    "AdaBoost": AdaBoostClassifier(n_estimators=200, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "SVC": SVC(probability=True, kernel='rbf'),
    "MLP (Sklearn)": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "CatBoost": CatBoostClassifier(verbose=0, random_state=42),
    "Keras NN": KerasClassifier(build_fn=create_nn, epochs=30, batch_size=16, verbose=0)
}

# --- 5. Evaluation ---
results = {}
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    print(f"Training {name}...")
    pipe = Pipeline([("scaler", StandardScaler()), ("clf", model)])
    try:
        cv_scores = cross_val_score(pipe, X, y, cv=skf, scoring="roc_auc")
        results[name] = np.mean(cv_scores)
        print(f"{name}: ROC-AUC = {np.mean(cv_scores):.3f}")
    except Exception as e:
        print(f"{name} failed: {e}")

# Save results as JSON
os.makedirs("assets", exist_ok=True)
with open("assets/metrics.json", "w") as f:
    json.dump(results, f, indent=4)

# --- 6. Results Table ---
df_results = pd.DataFrame(list(results.items()), columns=["Model", "ROC-AUC"])
df_results = df_results.sort_values(by="ROC-AUC", ascending=False)
print(df_results)

# Plot results
plt.figure(figsize=(8,5))
sns.barplot(x="ROC-AUC", y="Model", data=df_results, palette="Blues_r")
plt.title("Model Comparison (ROC-AUC)")
plt.savefig("assets/model_comparison.png")
plt.show()

# --- 7. Best Model ---
best_name = df_results.iloc[0]["Model"]
best_auc = df_results.iloc[0]["ROC-AUC"]
print(f"Best model: {best_name} (ROC-AUC = {best_auc:.3f})")

best_model = Pipeline([("scaler", StandardScaler()), ("clf", models[best_name])])
best_model.fit(X, y)
os.makedirs("models", exist_ok=True)
joblib.dump(best_model, "models/best_model.joblib")

# --- 8. Confusion Matrix ---
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, classification_report

y_pred = best_model.predict(X)
cm = confusion_matrix(y, y_pred)
plt.figure(figsize=(5,5))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Healthy", "Parkinsonâ€™s"])
disp.plot(cmap="Blues", values_format="d")
plt.title(f"Confusion Matrix - {best_name}")
plt.savefig("assets/confusion_matrix.png")
plt.show()

# --- 9. ROC Curve ---
y_pred_prob = best_model.predict_proba(X)[:,1]
fpr, tpr, _ = roc_curve(y, y_pred_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"AUC = {roc_auc:.2f}")
plt.plot([0,1], [0,1], color="navy", lw=2, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(f"ROC Curve - {best_name}")
plt.legend(loc="lower right")
plt.savefig("assets/roc_curve.png")
plt.show()

# --- 10. Classification Report ---
report = classification_report(y, y_pred, target_names=["Healthy", "Parkinsonâ€™s"])
print("Classification Report:\n", report)
with open("assets/metrics_report.txt", "w") as f:
    f.write(report)

# --- 11. Feature Importance ---
if hasattr(best_model.named_steps["clf"], "feature_importances_"):
    importances = best_model.named_steps["clf"].feature_importances_
    feat_imp = pd.DataFrame({"Feature": X.columns, "Importance": importances})
    feat_imp = feat_imp.sort_values("Importance", ascending=False)

    plt.figure(figsize=(8,5))
    sns.barplot(x="Importance", y="Feature", data=feat_imp.head(15), palette="viridis")
    plt.title(f"Top Feature Importances - {best_name}")
    plt.tight_layout()
    plt.savefig("assets/feature_importance.png")
    plt.show()
